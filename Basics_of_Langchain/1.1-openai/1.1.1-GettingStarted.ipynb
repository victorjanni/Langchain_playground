{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "#langsmith tracking \n",
    "os.environ['LANGSMITH_API_KEY']=os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'text_inputs': True, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'text_outputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x0000027BB63AE500> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027BD32BF010> root_client=<openai.OpenAI object at 0x0000027BB63AE290> root_async_client=<openai.AsyncOpenAI object at 0x0000027BD32BEF80> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model='gpt-4o')\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input and get response\n",
    "result=llm.invoke(\"what is AGI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='AGI stands for Artificial General Intelligence. It refers to a form of artificial intelligence that possesses the ability to understand, learn, and apply knowledge across a broad range of tasks at a level equal to or greater than that of a human being. Unlike narrow AI, which is designed to perform specific tasks (such as language translation or facial recognition) efficiently, AGI would have the capacity to handle any intellectual task that a human can.\\n\\nThe development of AGI represents a significant challenge and goal within the field of AI research. It would require the creation of systems that have general cognitive abilities, including understanding, reasoning, problem-solving, and learning from experience in a way that is not limited by predefined constraints or applications. As of now, AGI remains a theoretical concept, as no AI or machine learning system has achieved this level of sophistication.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 167, 'prompt_tokens': 12, 'total_tokens': 179, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a2afb0f9e7', 'id': 'chatcmpl-DATM4TUU6SwP6ftSAJ6Z2vD3RQ4I7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c6efb-52ad-7ae3-8172-47598c528dff-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 12, 'output_tokens': 167, 'total_tokens': 179, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert of Ai engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prompt template \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are an expert of Ai engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangSmith is a tool developed by LangChain that assists developers in debugging and testing large language model (LLM) applications. It provides features such as logging, visualizing, and analyzing the interactions between applications and language models, which helps in identifying issues and improving the performance of these applications. LangSmith is aimed at making the process of working with LLMs more efficient and effective.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 31, 'total_tokens': 108, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a3cb6d4ca8', 'id': 'chatcmpl-DATM65sXXnb1wxY1KN5zbccsliCiE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c6efb-5db4-75f1-a94c-8d8ee6bc68a7-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 31, 'output_tokens': 77, 'total_tokens': 108, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#chain\n",
    "chain=prompt|llm\n",
    "response=chain.invoke({\"input\":\"what is langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a toolset developed by LangChain designed to enhance the building, testing, and monitoring of applications that use large language models (LLMs). It provides developers with the ability to gain deeper insights into how their language model applications perform, identify potential issues, and optimize workflows. LangSmith includes capabilities such as collecting detailed traces of model interactions, comparing performance across different versions of prompts, and understanding user behavior to better tailor responses. It serves as a valuable toolset for developers looking to create robust and reliable AI applications using language models.\n"
     ]
    }
   ],
   "source": [
    "## stroutput parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "response=chain.invoke({\"input\":\"what is langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
